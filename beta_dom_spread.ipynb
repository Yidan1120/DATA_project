{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime: ~3 hrs\n",
    "## Extracting beta, dom & spread for each stock across all time_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "* Compute_beta: Computes beta value from stock wap, mean(stock wap), mean(all stock waps), mean(all stock waps / sec))\n",
    "* Extract_features: Returns dataframe with beta, mean(depth of market) & mean(spread) for all stocks @ a selected time_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta(d):\n",
    "    \"\"\"\n",
    "    Computes beta value from stock wap, mean(stock wap), mean(all stock waps), mean(all stock waps / sec))\n",
    "    \"\"\"\n",
    "    c = (((d['wap'] - d['wap_mean']) * (d['market_mean_seconds'] - d['market_mean'])) / len(d)).sum()\n",
    "    v = (((d['market_mean_seconds'] - d['market_mean']) ** 2) / len(d)).sum()\n",
    "    d['beta'] = c/v\n",
    "    return d\n",
    "\n",
    "def extract_features(files, time_id = 5):\n",
    "    \"\"\"\n",
    "    Returns dataframe with beta, mean(depth of market) & mean(spread) for all stocks @ a selected time_id\n",
    "    \"\"\"\n",
    "    # CREATE NEW DATAFRAME - with columns: stock_id and average wap for time_id\n",
    "    stocks = pd.DataFrame({\"stock_id\":[], \"wap\":[], \"seconds\": []})\n",
    "\n",
    "    # For each stock...\n",
    "    for f in files[:]: \n",
    "        # LAZY READ TO OPTIMIZE READ TIME\n",
    "        df = dd.read_csv(f)\n",
    "\n",
    "        # FIND ONLY COLUMNS WITH time_id ONLY\n",
    "        df = df[df['time_id'] == time_id]\n",
    "        df = df.compute()\n",
    "\n",
    "        # COMPUTE FEATURES\n",
    "        df[\"wap\"] = (df[\"bid_price1\"] * df[\"ask_size1\"] + df[\"ask_price1\"] * df[\"bid_size1\"]) \\\n",
    "                    / (df[\"bid_size1\"] + df[\"ask_size1\"])\n",
    "        \n",
    "        df[\"dom\"] = df['bid_price1'] * df['bid_size1'] + df['bid_price2'] * df['bid_size2'] \\\n",
    "                    + df['ask_price1'] * df['ask_size1'] + df['ask_price2'] * df['ask_size2']\n",
    "        \n",
    "        df[\"spread\"] = df['ask_price1'] / df['bid_price1'] - 1\n",
    "        \n",
    "        d = pd.DataFrame({\"stock_id\": df[\"stock_id\"], \"wap\": df[\"wap\"], \"dom\": df[\"dom\"], \"spread\": df[\"spread\"],\n",
    "                          \"seconds\": df[\"seconds_in_bucket\"]})\n",
    "        \n",
    "        ## FILLING ALL SECONDS WITH STATS FROM SECOND BEFORE (NO MISSING SECONDS)\n",
    "        d = d.reset_index(drop = True)\n",
    "        i = 0\n",
    "        while i < 600: \n",
    "            if i == len(d) and i < 600 or d.loc[i].seconds > i:\n",
    "                new = pd.DataFrame({'stock_id':[d.loc[i-1].stock_id], \n",
    "                                    'wap':[d.loc[i-1].wap], \n",
    "                                    'dom':[d.loc[i-1].dom], \n",
    "                                    'spread':[d.loc[i-1].spread], \n",
    "                                    'seconds':[i]})\n",
    "\n",
    "                d = pd.concat([d, new]).sort_values('seconds')\n",
    "                d = d.reset_index(drop=True)\n",
    "            i += 1\n",
    "        \n",
    "        stocks = pd.concat([stocks, d]).astype({'stock_id':'int', 'seconds':'int'})\n",
    "    \n",
    "    # COMPUTE FEATURES ACROSS ALL STOCKS FOR TIME_ID\n",
    "    \n",
    "    # Calculate average wap for each stock_id for time_id\n",
    "    stocks['wap_mean'] = stocks.groupby(['stock_id'])['wap'].transform('mean')\n",
    "\n",
    "    # Calculate market mean for each second of time_id (mean WAP/sec across all stocks)\n",
    "    stocks['market_mean_seconds'] = stocks.groupby(['seconds'])['wap'].transform('mean')\n",
    "\n",
    "    # Calculate overall market mean for time_id (mean WAP across all stocks)\n",
    "    stocks['market_mean'] = stocks['wap'].mean()\n",
    "    \n",
    "    # compute beta for each stock_id for time_id\n",
    "    stocks = stocks.groupby(['stock_id']).apply(compute_beta)\n",
    "    \n",
    "    # Calculate average dom for each stock_id for time_id\n",
    "    stocks['dom_mean'] = stocks.groupby(['stock_id'])['dom'].transform('mean')\n",
    "    \n",
    "    # Calculate average spread for each stock_id for time_id\n",
    "    stocks['spread_mean'] = stocks.groupby(['stock_id'])['spread'].transform('mean')\n",
    "    \n",
    "    stock_betas = pd.DataFrame({\n",
    "        'stock_id': stocks['stock_id'].unique(), \n",
    "        'beta': stocks['beta'].unique(),\n",
    "        'dom': stocks['dom_mean'].unique(),\n",
    "        'spread': stocks['spread_mean'].unique()\n",
    "    })\n",
    "    \n",
    "    return stock_betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute beta, mean dom & mean spread for each time_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(\"./individual_book_train\", \"*.csv\"))\n",
    "stocks = pd.DataFrame({'stock_id':[], 'beta':[], 'dom':[], 'spread':[]})\n",
    "\n",
    "# for each time_id in all unique time_ids from first file (assumption all time_ids are shared across stocks)\n",
    "for time_id in pd.read_csv(files[0]).time_id.unique():\n",
    "    \n",
    "    # merge extracted features for each stock by time_id\n",
    "    stocks = pd.concat([stocks, extract_features(files, time_id)]).astype({'stock_id':'int'})\n",
    "\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Across all time_ids, compute mean beta, mean(mean dom & mean spread for each time_id) for all stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging beta, dom & spread across time_ids for each stock\n",
    "stocks['beta_mean'] = stocks.groupby(['stock_id'])['beta'].mean()\n",
    "stocks['dom_mean'] = stocks.groupby(['stock_id'])['dom'].mean()\n",
    "stocks['spread_mean'] = stocks.groupby(['stock_id'])['spread'].mean()\n",
    "\n",
    "# storing averaged beta, dom & spread in dataframe for each stock\n",
    "stock_final = pd.DataFrame({\n",
    "    'stock_id': stocks['stock_id'].unique(),\n",
    "    'beta': stocks['beta_mean'].unique(),\n",
    "    'dom': stocks['dom_mean'].unique(),\n",
    "    'spread': stocks['spread_mean'].unique()\n",
    "})\n",
    "\n",
    "stock_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write all extracted features to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contains averaged beta, dom & spread for all stocks across all time_ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_final.to_csv(\"beta_dom_spread.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contains beta, dom & spread for all stocks for each time_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.to_csv(\"beta_dom_spread_by_timeid.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
