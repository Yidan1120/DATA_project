{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c68f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcbdae4",
   "metadata": {},
   "source": [
    "### Concat using time_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb29b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(\"./individual_book_train\", \"*.csv\"))\n",
    "\n",
    "def concat_stocks(files, time_id = 5):\n",
    "    \n",
    "    # CREATE NEW DATAFRAME - with columns: stock_id and average wap for time_id\n",
    "    stocks = pd.DataFrame({\"stock_id\":[], \"wap\":[], \"seconds\": []})\n",
    "    \n",
    "    for f in files[:]: \n",
    "\n",
    "        # LAZY READ TO OPTIMIZE READ TIME\n",
    "        df = dd.read_csv(f)\n",
    "\n",
    "        # FIND ONLY COLUMNS WITH time_id ONLY\n",
    "        df = df[df['time_id'] == time_id]\n",
    "        df = df.compute()\n",
    "        \n",
    "        # COMPUTE WAP COLUMN\n",
    "        df[\"wap\"] = (df[\"bid_price1\"] * df[\"ask_size1\"] + df[\"ask_price1\"] * df[\"bid_size1\"]) \\\n",
    "                    / (df[\"bid_size1\"] + df[\"ask_size1\"])\n",
    "        \n",
    "        d = pd.DataFrame({\"stock_id\": df[\"stock_id\"], \"wap\": df[\"wap\"], \"seconds\": df[\"seconds_in_bucket\"]})\n",
    "        \n",
    "        ## FILLING ALL SECONDS WITH STATS FROM SECOND BEFORE (NO MISSING SECONDS)\n",
    "        i = 0\n",
    "        while i < 600: \n",
    "            if i == len(d) and i < 600 or d.loc[i].seconds > i:\n",
    "                new = pd.DataFrame({'stock_id':[d.loc[i-1].stock_id], 'wap':[d.loc[i-1].wap], 'seconds':[i]})\n",
    "                d = pd.concat([d, new]).sort_values('seconds')\n",
    "                d = d.reset_index(drop=True)\n",
    "        \n",
    "            i += 1\n",
    "    \n",
    "        stocks = pd.concat([stocks, d]).astype({'stock_id':'int', 'seconds':'int'})\n",
    "                \n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01b894",
   "metadata": {},
   "source": [
    "### Creating dataframe (may take some time)\n",
    "- All stocks concatenated by time id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = concat_stocks(files, time_id = 5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ab80e",
   "metadata": {},
   "source": [
    "## Computing Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722363b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta(d):\n",
    "    \"\"\"\n",
    "    Computes Beta coeff as Covariance(Stock,Market)/Variance(Market)\n",
    "    Details found here: https://corporatefinanceinstitute.com/resources/data-science/beta-coefficient/\n",
    "    \"\"\"\n",
    "    c = (((d['wap'] - d['wap_mean']) * (d['market_mean_seconds'] - d['market_mean'])) / len(d)).sum()\n",
    "    #v = (((d['market_mean_seconds'] - d['market_mean']) ** 2) / len(d)).sum()\n",
    "    d['beta'] = c/np.var(d['market_mean_seconds'])\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average wap for stock\n",
    "s['wap_mean'] = s.groupby(['stock_id'])['wap'].transform('mean')\n",
    "\n",
    "# Calculate market mean for each second\n",
    "s['market_mean_seconds'] = s.groupby(['seconds'])['wap'].transform('mean')\n",
    "\n",
    "# Calculate overall market mean \n",
    "s['market_mean'] = s['wap'].mean()\n",
    "\n",
    "# compute beta for each stock_id\n",
    "s = s.groupby(['stock_id']).apply(compute_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ed80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_betas = pd.DataFrame({'stock_id':s['stock_id'].unique(), 'beta':s['beta'].unique()})\n",
    "\n",
    "stock_betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80180942",
   "metadata": {},
   "source": [
    "### MeanShift (num clusters decided by data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "sb = stock_betas\n",
    "X = np.reshape(sb['beta'].values, (-1,1))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift(bandwidth=None, bin_seeding=True)\n",
    "ms.fit(X)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4a303",
   "metadata": {},
   "source": [
    "### K-means (num clusters will need be decided) - atm using Elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14186dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "wcss = []\n",
    "\n",
    "sb = stock_betas\n",
    "X = np.reshape(sb['beta'].values, (-1,1))\n",
    "X\n",
    "\n",
    "for i in range(2, 17):\n",
    "    kmeans = KMeans(n_clusters = i, init = \"k-means++\", max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(range(2, 17), wcss)\n",
    "plt.title('The elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS') #within cluster sum of squares\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(6)\n",
    "\n",
    "clusts = km.fit_predict(X)\n",
    "clusts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc81136",
   "metadata": {},
   "source": [
    "## Assigning Cluster IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7727bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_betas['cluster_id'] = clusts\n",
    "stock_betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b479cb2",
   "metadata": {},
   "source": [
    "### Analysing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_betas.boxplot(column = 'beta', by='cluster_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_betas.groupby(['cluster_id'])['beta'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314afaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_betas.groupby(['cluster_id'])['beta'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_betas.groupby(['cluster_id'])['beta'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d098a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfb7015e",
   "metadata": {},
   "source": [
    "### Extra: Code found online for comparing cluster quality with selected K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "X_segmentation = X\n",
    "\n",
    "search_range = range(2, 18)\n",
    "report = {}\n",
    "for k in search_range:\n",
    "    temp_dict = {}\n",
    "    kmeans = KMeans(k)\n",
    "    #inertia = kmeans.inertia_\n",
    "    #temp_dict['Sum of squared error'] = inertia\n",
    "    \n",
    "    cluster = kmeans.fit_predict(X_segmentation)\n",
    "    \n",
    "    inertia = kmeans.inertia_\n",
    "    temp_dict['Sum of squared error'] = inertia\n",
    "    chs = metrics.calinski_harabasz_score(X_segmentation, cluster)\n",
    "    ss = metrics.silhouette_score(X_segmentation, cluster)\n",
    "    temp_dict['Calinski Harabasz Score'] = chs\n",
    "    temp_dict['Silhouette Score'] = ss\n",
    "    report[k] = temp_dict\n",
    "    \n",
    "\n",
    "report_df = pd.DataFrame(report).T\n",
    "report_df.plot(figsize=(15, 10),\n",
    "               xticks=search_range,\n",
    "               grid=True,\n",
    "               title=f'Selecting optimal \"K\"',\n",
    "               subplots=True,\n",
    "               marker='o',\n",
    "               sharex=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5083fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yellowbrick\n",
    "from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "\n",
    "kelbow_visualizer(KMeans(random_state=1),\n",
    "                  X_segmentation,\n",
    "                  k=(2, 19),\n",
    "                  timings=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
